{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InDzVlKc5Uu6",
        "outputId": "56312986-301e-40e9-e42c-2e8e10f0fd05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2CDafMpL5XAN"
      },
      "outputs": [],
      "source": [
        "drive_path = \"/content/drive/MyDrive/dat1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qCxzyIOW5bTn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import  Conv2D, MaxPool2D, BatchNormalization, Activation, Input , Conv2DTranspose, Concatenate\n",
        "from tensorflow.keras.models import Model, load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_ZDLpUza5fpx"
      },
      "outputs": [],
      "source": [
        "\n",
        "batch_size = 2\n",
        "learning_rate = 1e-4\n",
        "epochs = 40\n",
        "height = 720\n",
        "width = 1280"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sfKgoIAE8waP"
      },
      "outputs": [],
      "source": [
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9MZSMAQB6Uq5"
      },
      "outputs": [],
      "source": [
        "dataset_path = os.path.join(\"/content/drive/MyDrive/dat2\", \"augmented\")\n",
        "files_dir = os.path.join(drive_path, 'Colab Notebooks',\"files\", \"augmented\")\n",
        "model_file= os.path.join(files_dir,\"pentagon.h5\")\n",
        "log_file = os.path.join(files_dir,\"loges-original.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3oEtvm4R63Wl"
      },
      "outputs": [],
      "source": [
        "def load_data(path):\n",
        "    train_x = sorted(glob(os.path.join(path,\"train\",\"images\",\"*\")))\n",
        "    train_y = sorted(glob(os.path.join(path,\"train\",\"masks\",\"*\")))\n",
        "\n",
        "    valid_x = sorted(glob(os.path.join(path,\"valid\",\"images\",\"*\")))\n",
        "    valid_y = sorted(glob(os.path.join(path,\"valid\",\"masks\",\"*\")))\n",
        "\n",
        "    return (train_x,train_y) , (valid_x,valid_y)\n",
        "\n",
        "#reading the image\n",
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path,cv2.IMREAD_COLOR)\n",
        "    x = x/255.0\n",
        "    return x\n",
        "\n",
        "#reading the mask\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    x = x/255.0\n",
        "    x = np.expand_dims(x, axis=-1)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "smvF5qt47EDX"
      },
      "outputs": [],
      "source": [
        "#tf data pipeline\n",
        "\n",
        "def tf_parse(x,y):\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        return x, y\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\n",
        "    x.set_shape([height, width, 3])\n",
        "    y.set_shape([height, width, 1])\n",
        "    return x, y\n",
        "\n",
        "def tf_dataset(x, y, batch=4):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    dataset = dataset.map(tf_parse, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "XV4ZBsSC7YiN"
      },
      "outputs": [],
      "source": [
        "model = load_model(model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNf1qHq9RcKg",
        "outputId": "5e71a74f-d281-4706-b0d4-409ec812a465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"unet\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 720, 1280, 3)]       0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 720, 1280, 64)        1792      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 720, 1280, 64)        256       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 720, 1280, 64)        0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 720, 1280, 64)        36928     ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 720, 1280, 64)        256       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 720, 1280, 64)        0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 360, 640, 64)         0         ['activation_1[0][0]']        \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 360, 640, 128)        73856     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 360, 640, 128)        512       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 360, 640, 128)        0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 360, 640, 128)        147584    ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 360, 640, 128)        512       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 360, 640, 128)        0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 180, 320, 128)        0         ['activation_3[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 180, 320, 256)        295168    ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 180, 320, 256)        1024      ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 180, 320, 256)        0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 180, 320, 256)        590080    ['activation_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 180, 320, 256)        1024      ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 180, 320, 256)        0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 90, 160, 256)         0         ['activation_5[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 90, 160, 512)         1180160   ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 90, 160, 512)         2048      ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 90, 160, 512)         0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 90, 160, 512)         2359808   ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 90, 160, 512)         2048      ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 90, 160, 512)         0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 45, 80, 512)          0         ['activation_7[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 45, 80, 1024)         4719616   ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 45, 80, 1024)         4096      ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 45, 80, 1024)         0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 45, 80, 1024)         9438208   ['activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 45, 80, 1024)         4096      ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 45, 80, 1024)         0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTr  (None, 90, 160, 512)         2097664   ['activation_9[0][0]']        \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 90, 160, 1024)        0         ['conv2d_transpose[0][0]',    \n",
            "                                                                     'activation_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 90, 160, 512)         4719104   ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 90, 160, 512)         2048      ['conv2d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 90, 160, 512)         0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 90, 160, 512)         2359808   ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 90, 160, 512)         2048      ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 90, 160, 512)         0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2D  (None, 180, 320, 256)        524544    ['activation_11[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 180, 320, 512)        0         ['conv2d_transpose_1[0][0]',  \n",
            " )                                                                   'activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 180, 320, 256)        1179904   ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 180, 320, 256)        1024      ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 180, 320, 256)        0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 180, 320, 256)        590080    ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 180, 320, 256)        1024      ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 180, 320, 256)        0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2D  (None, 360, 640, 128)        131200    ['activation_13[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 360, 640, 256)        0         ['conv2d_transpose_2[0][0]',  \n",
            " )                                                                   'activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 360, 640, 128)        295040    ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 360, 640, 128)        512       ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 360, 640, 128)        0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 360, 640, 128)        147584    ['activation_14[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 360, 640, 128)        512       ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 360, 640, 128)        0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2D  (None, 720, 1280, 64)        32832     ['activation_15[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 720, 1280, 128)       0         ['conv2d_transpose_3[0][0]',  \n",
            " )                                                                   'activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 720, 1280, 64)        73792     ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 720, 1280, 64)        256       ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 720, 1280, 64)        0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 720, 1280, 64)        36928     ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 720, 1280, 64)        256       ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 720, 1280, 64)        0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 720, 1280, 1)         65        ['activation_17[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31055297 (118.47 MB)\n",
            "Trainable params: 31043521 (118.42 MB)\n",
            "Non-trainable params: 11776 (46.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "aw2rNzvE7PFk"
      },
      "outputs": [],
      "source": [
        "(train_x,train_y) , (valid_x,valid_y) = load_data(dataset_path)\n",
        "\n",
        "train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
        "valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "No2wXCfb7U63"
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"acc\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xQ90xqWGQYFp"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "\n",
        "    ModelCheckpoint(model_file,verbose=1,save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\",factor=0.1,patience=4),\n",
        "    CSVLogger(log_file),\n",
        "    EarlyStopping(monitor='val_loss',patience=20, restore_best_weights= False)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48Jt30Jb8sHH",
        "outputId": "3c6ec91c-eba7-43fb-fe75-593b379247ba"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.1310 - acc: 0.9474\n",
            "Epoch 1: val_loss improved from inf to 0.30434, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "984/984 [==============================] - 523s 499ms/step - loss: 0.1310 - acc: 0.9474 - val_loss: 0.3043 - val_acc: 0.9030 - lr: 1.0000e-04\n",
            "Epoch 2/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.1027 - acc: 0.9586\n",
            "Epoch 2: val_loss did not improve from 0.30434\n",
            "984/984 [==============================] - 471s 478ms/step - loss: 0.1027 - acc: 0.9586 - val_loss: 0.3271 - val_acc: 0.9114 - lr: 1.0000e-04\n",
            "Epoch 3/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0897 - acc: 0.9646\n",
            "Epoch 3: val_loss improved from 0.30434 to 0.21008, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 475s 483ms/step - loss: 0.0897 - acc: 0.9646 - val_loss: 0.2101 - val_acc: 0.9142 - lr: 1.0000e-04\n",
            "Epoch 4/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0855 - acc: 0.9657\n",
            "Epoch 4: val_loss improved from 0.21008 to 0.10518, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 475s 483ms/step - loss: 0.0855 - acc: 0.9657 - val_loss: 0.1052 - val_acc: 0.9595 - lr: 1.0000e-04\n",
            "Epoch 5/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0798 - acc: 0.9681\n",
            "Epoch 5: val_loss did not improve from 0.10518\n",
            "984/984 [==============================] - 472s 479ms/step - loss: 0.0798 - acc: 0.9681 - val_loss: 0.1257 - val_acc: 0.9545 - lr: 1.0000e-04\n",
            "Epoch 6/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0760 - acc: 0.9692\n",
            "Epoch 6: val_loss did not improve from 0.10518\n",
            "984/984 [==============================] - 472s 479ms/step - loss: 0.0760 - acc: 0.9692 - val_loss: 0.1357 - val_acc: 0.9450 - lr: 1.0000e-04\n",
            "Epoch 7/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0690 - acc: 0.9719\n",
            "Epoch 7: val_loss improved from 0.10518 to 0.08707, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 476s 484ms/step - loss: 0.0690 - acc: 0.9719 - val_loss: 0.0871 - val_acc: 0.9647 - lr: 1.0000e-04\n",
            "Epoch 8/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0667 - acc: 0.9727\n",
            "Epoch 8: val_loss improved from 0.08707 to 0.08154, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 477s 484ms/step - loss: 0.0667 - acc: 0.9727 - val_loss: 0.0815 - val_acc: 0.9681 - lr: 1.0000e-04\n",
            "Epoch 9/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0623 - acc: 0.9742\n",
            "Epoch 9: val_loss did not improve from 0.08154\n",
            "984/984 [==============================] - 473s 480ms/step - loss: 0.0623 - acc: 0.9742 - val_loss: 0.1153 - val_acc: 0.9611 - lr: 1.0000e-04\n",
            "Epoch 10/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0581 - acc: 0.9760\n",
            "Epoch 10: val_loss did not improve from 0.08154\n",
            "984/984 [==============================] - 472s 480ms/step - loss: 0.0581 - acc: 0.9760 - val_loss: 0.1433 - val_acc: 0.9533 - lr: 1.0000e-04\n",
            "Epoch 11/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0566 - acc: 0.9764\n",
            "Epoch 11: val_loss did not improve from 0.08154\n",
            "984/984 [==============================] - 472s 480ms/step - loss: 0.0566 - acc: 0.9764 - val_loss: 0.1177 - val_acc: 0.9589 - lr: 1.0000e-04\n",
            "Epoch 12/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0531 - acc: 0.9775\n",
            "Epoch 12: val_loss improved from 0.08154 to 0.05615, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 476s 484ms/step - loss: 0.0531 - acc: 0.9775 - val_loss: 0.0561 - val_acc: 0.9731 - lr: 1.0000e-04\n",
            "Epoch 13/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0516 - acc: 0.9778\n",
            "Epoch 13: val_loss improved from 0.05615 to 0.05226, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 477s 484ms/step - loss: 0.0516 - acc: 0.9778 - val_loss: 0.0523 - val_acc: 0.9752 - lr: 1.0000e-04\n",
            "Epoch 14/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0495 - acc: 0.9784\n",
            "Epoch 14: val_loss improved from 0.05226 to 0.04011, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 477s 484ms/step - loss: 0.0495 - acc: 0.9784 - val_loss: 0.0401 - val_acc: 0.9803 - lr: 1.0000e-04\n",
            "Epoch 15/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0474 - acc: 0.9791\n",
            "Epoch 15: val_loss improved from 0.04011 to 0.03016, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 478s 484ms/step - loss: 0.0474 - acc: 0.9791 - val_loss: 0.0302 - val_acc: 0.9843 - lr: 1.0000e-04\n",
            "Epoch 16/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0471 - acc: 0.9793\n",
            "Epoch 16: val_loss did not improve from 0.03016\n",
            "984/984 [==============================] - 473s 480ms/step - loss: 0.0471 - acc: 0.9793 - val_loss: 0.0490 - val_acc: 0.9769 - lr: 1.0000e-04\n",
            "Epoch 17/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0458 - acc: 0.9796\n",
            "Epoch 17: val_loss did not improve from 0.03016\n",
            "984/984 [==============================] - 473s 480ms/step - loss: 0.0458 - acc: 0.9796 - val_loss: 0.0451 - val_acc: 0.9776 - lr: 1.0000e-04\n",
            "Epoch 18/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0429 - acc: 0.9806\n",
            "Epoch 18: val_loss did not improve from 0.03016\n",
            "984/984 [==============================] - 473s 481ms/step - loss: 0.0429 - acc: 0.9806 - val_loss: 0.0427 - val_acc: 0.9789 - lr: 1.0000e-04\n",
            "Epoch 19/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0412 - acc: 0.9812\n",
            "Epoch 19: val_loss did not improve from 0.03016\n",
            "984/984 [==============================] - 473s 481ms/step - loss: 0.0412 - acc: 0.9812 - val_loss: 0.0547 - val_acc: 0.9760 - lr: 1.0000e-04\n",
            "Epoch 20/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0465 - acc: 0.9792\n",
            "Epoch 20: val_loss did not improve from 0.03016\n",
            "984/984 [==============================] - 473s 481ms/step - loss: 0.0465 - acc: 0.9792 - val_loss: 0.0343 - val_acc: 0.9816 - lr: 1.0000e-05\n",
            "Epoch 21/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0405 - acc: 0.9813\n",
            "Epoch 21: val_loss did not improve from 0.03016\n",
            "984/984 [==============================] - 473s 481ms/step - loss: 0.0405 - acc: 0.9813 - val_loss: 0.0321 - val_acc: 0.9831 - lr: 1.0000e-05\n",
            "Epoch 22/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0377 - acc: 0.9825\n",
            "Epoch 22: val_loss did not improve from 0.03016\n",
            "984/984 [==============================] - 473s 481ms/step - loss: 0.0377 - acc: 0.9825 - val_loss: 0.0305 - val_acc: 0.9840 - lr: 1.0000e-05\n",
            "Epoch 23/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0355 - acc: 0.9834\n",
            "Epoch 23: val_loss improved from 0.03016 to 0.02919, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 478s 486ms/step - loss: 0.0355 - acc: 0.9834 - val_loss: 0.0292 - val_acc: 0.9847 - lr: 1.0000e-05\n",
            "Epoch 24/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0337 - acc: 0.9842\n",
            "Epoch 24: val_loss improved from 0.02919 to 0.02795, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 478s 486ms/step - loss: 0.0337 - acc: 0.9842 - val_loss: 0.0280 - val_acc: 0.9853 - lr: 1.0000e-05\n",
            "Epoch 25/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0322 - acc: 0.9848\n",
            "Epoch 25: val_loss improved from 0.02795 to 0.02694, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 478s 485ms/step - loss: 0.0322 - acc: 0.9848 - val_loss: 0.0269 - val_acc: 0.9858 - lr: 1.0000e-05\n",
            "Epoch 26/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0308 - acc: 0.9853\n",
            "Epoch 26: val_loss improved from 0.02694 to 0.02615, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 478s 486ms/step - loss: 0.0308 - acc: 0.9853 - val_loss: 0.0261 - val_acc: 0.9862 - lr: 1.0000e-05\n",
            "Epoch 27/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0295 - acc: 0.9858\n",
            "Epoch 27: val_loss improved from 0.02615 to 0.02547, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 478s 485ms/step - loss: 0.0295 - acc: 0.9858 - val_loss: 0.0255 - val_acc: 0.9865 - lr: 1.0000e-05\n",
            "Epoch 28/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0283 - acc: 0.9862\n",
            "Epoch 28: val_loss improved from 0.02547 to 0.02478, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 478s 485ms/step - loss: 0.0283 - acc: 0.9862 - val_loss: 0.0248 - val_acc: 0.9867 - lr: 1.0000e-05\n",
            "Epoch 29/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0272 - acc: 0.9866\n",
            "Epoch 29: val_loss improved from 0.02478 to 0.02421, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 478s 485ms/step - loss: 0.0272 - acc: 0.9866 - val_loss: 0.0242 - val_acc: 0.9869 - lr: 1.0000e-05\n",
            "Epoch 30/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0262 - acc: 0.9869\n",
            "Epoch 30: val_loss improved from 0.02421 to 0.02378, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 478s 485ms/step - loss: 0.0262 - acc: 0.9869 - val_loss: 0.0238 - val_acc: 0.9870 - lr: 1.0000e-05\n",
            "Epoch 31/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0253 - acc: 0.9873\n",
            "Epoch 31: val_loss improved from 0.02378 to 0.02341, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 477s 485ms/step - loss: 0.0253 - acc: 0.9873 - val_loss: 0.0234 - val_acc: 0.9871 - lr: 1.0000e-05\n",
            "Epoch 32/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0244 - acc: 0.9875\n",
            "Epoch 32: val_loss improved from 0.02341 to 0.02303, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 477s 485ms/step - loss: 0.0244 - acc: 0.9875 - val_loss: 0.0230 - val_acc: 0.9872 - lr: 1.0000e-05\n",
            "Epoch 33/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0236 - acc: 0.9878\n",
            "Epoch 33: val_loss improved from 0.02303 to 0.02272, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 477s 485ms/step - loss: 0.0236 - acc: 0.9878 - val_loss: 0.0227 - val_acc: 0.9873 - lr: 1.0000e-05\n",
            "Epoch 34/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0228 - acc: 0.9881\n",
            "Epoch 34: val_loss improved from 0.02272 to 0.02244, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 478s 485ms/step - loss: 0.0228 - acc: 0.9881 - val_loss: 0.0224 - val_acc: 0.9874 - lr: 1.0000e-05\n",
            "Epoch 35/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0221 - acc: 0.9883\n",
            "Epoch 35: val_loss improved from 0.02244 to 0.02220, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 478s 485ms/step - loss: 0.0221 - acc: 0.9883 - val_loss: 0.0222 - val_acc: 0.9875 - lr: 1.0000e-05\n",
            "Epoch 36/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0214 - acc: 0.9886\n",
            "Epoch 36: val_loss improved from 0.02220 to 0.02206, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 481s 488ms/step - loss: 0.0214 - acc: 0.9886 - val_loss: 0.0221 - val_acc: 0.9875 - lr: 1.0000e-05\n",
            "Epoch 37/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0208 - acc: 0.9888\n",
            "Epoch 37: val_loss improved from 0.02206 to 0.02190, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 478s 485ms/step - loss: 0.0208 - acc: 0.9888 - val_loss: 0.0219 - val_acc: 0.9875 - lr: 1.0000e-05\n",
            "Epoch 38/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0201 - acc: 0.9890\n",
            "Epoch 38: val_loss improved from 0.02190 to 0.02178, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 479s 486ms/step - loss: 0.0201 - acc: 0.9890 - val_loss: 0.0218 - val_acc: 0.9876 - lr: 1.0000e-05\n",
            "Epoch 39/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0195 - acc: 0.9892\n",
            "Epoch 39: val_loss improved from 0.02178 to 0.02169, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 478s 486ms/step - loss: 0.0195 - acc: 0.9892 - val_loss: 0.0217 - val_acc: 0.9876 - lr: 1.0000e-05\n",
            "Epoch 40/40\n",
            "984/984 [==============================] - ETA: 0s - loss: 0.0190 - acc: 0.9893\n",
            "Epoch 40: val_loss improved from 0.02169 to 0.02162, saving model to /content/drive/MyDrive/dat1/Colab Notebooks/files/augmented/pentagon.h5\n",
            "984/984 [==============================] - 478s 485ms/step - loss: 0.0190 - acc: 0.9893 - val_loss: 0.0216 - val_acc: 0.9876 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7973d0653be0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=valid_dataset,\n",
        "    epochs = epochs,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "jeoD0eTISS9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e7ee5e0-287a-45f3-b2b0-63c2ef9ab417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hej\n"
          ]
        }
      ],
      "source": [
        "print(\"hej\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X16GoayD3aFp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}